{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import datetime        \n",
    "from time import sleep\n",
    "import random\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.1 was released Friday October 25, 2024.\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id='fKSnwxwrgn7DXbSDq8oHnw',         # Your app's client ID\n",
    "    client_secret='xtz8CGEQjdB4SNbM9eHTp82eP0sIdQ', # Your app's client secret\n",
    "    user_agent='Copenhagen University Data Collection Course, analyzing comment civility, Oliver',       # A descriptive user agent\n",
    "    username='OkMinute',    # Your Reddit username\n",
    "    password='Fodbold7'     # Your Reddit password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_posts(subreddit_list, limit=1000, sort_by='top', time_filter='all'):\n",
    "    \"\"\"\n",
    "    Fetch top posts from a list of subreddits and return as a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        subreddit_list (list): List of subreddit names.\n",
    "        limit (int): Number of posts to fetch per subreddit.\n",
    "        sort_by (str): Sorting method ('top', 'hot', 'new', 'rising').\n",
    "        time_filter (str): Time filter for sorting ('all', 'day', 'hour', 'month', 'week', 'year'). Only for 'top'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing post data.\n",
    "    \"\"\"\n",
    "    \n",
    "    post_list = []\n",
    "    \n",
    "    for subreddit_name in subreddit_list:\n",
    "        try:\n",
    "            subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "            if sort_by == 'top':\n",
    "                posts = subreddit.top(limit=limit, time_filter=time_filter)\n",
    "            elif sort_by == 'hot':\n",
    "                posts = subreddit.hot(limit=limit)\n",
    "            elif sort_by == 'new':\n",
    "                posts = subreddit.new(limit=limit)\n",
    "            elif sort_by == 'rising':\n",
    "                posts = subreddit.rising(limit=limit)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid sort_by value. Use 'top', 'hot', 'new', or 'rising'.\")\n",
    "            \n",
    "            for post in posts:\n",
    "                post_list.append({\n",
    "                    'subreddit': subreddit_name,\n",
    "                    'title': post.title,\n",
    "                    'score': post.score,\n",
    "                    'id': post.id,\n",
    "                    'url': post.url,\n",
    "                    'num_comments': post.num_comments,\n",
    "                    'created_utc': post.created_utc,\n",
    "                    'selftext': post.selftext,\n",
    "                    'author': post.author.name if post.author else None,\n",
    "                    'upvote_ratio': post.upvote_ratio,\n",
    "                    'permalink': post.permalink,\n",
    "                    'domain': post.domain,\n",
    "                    'flair_text': post.link_flair_text,\n",
    "                    'is_self': post.is_self,\n",
    "                    'view_count': post.view_count,\n",
    "                    'media': post.media\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching posts from r/{subreddit_name}: {e}. Skipping...\")\n",
    "\n",
    "    return pd.DataFrame(post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_comments(post, max_comments=50):\n",
    "    \"\"\"\n",
    "    Fetch up to max_comments for a given post object.\n",
    "    \n",
    "    Parameters:\n",
    "        post (praw.models.Submission): The Reddit post object.\n",
    "        max_comments (int): Maximum number of comments to fetch.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing comment data.\n",
    "    \"\"\"\n",
    "    post.comments.replace_more(limit=0)  # Flatten all comments\n",
    "\n",
    "    comment_list = []\n",
    "    for i, comment in enumerate(post.comments.list()):\n",
    "        if i >= max_comments:\n",
    "            break\n",
    "\n",
    "        comment_list.append({\n",
    "            'subreddit': post.subreddit.display_name,\n",
    "            'post_id': post.id,\n",
    "            'post_title': post.title,\n",
    "            'comment_id': comment.id,\n",
    "            'author': comment.author.name if comment.author else None,\n",
    "            'score': comment.score,\n",
    "            'created_utc': comment.created_utc,\n",
    "            'body': comment.body,\n",
    "            'parent_id': comment.parent_id,\n",
    "            'depth': comment.depth,\n",
    "            'controversiality': comment.controversiality\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(comment_list)\n",
    "\n",
    "import time\n",
    "\n",
    "def get_all_comments(df_posts):\n",
    "    \"\"\"\n",
    "    Loop over posts DataFrame and collect all comments for each post with progress tracking.\n",
    "    \n",
    "    Parameters:\n",
    "        df_posts (pd.DataFrame): DataFrame containing posts.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing all collected comments.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_comments = []\n",
    "    for _, post in tqdm(df_posts.iterrows(), total=len(df_posts), desc=\"Fetching Comments\"):\n",
    "\n",
    "        # Check API rate limits\n",
    "        limits = reddit.auth.limits\n",
    "        if limits[\"remaining\"] < 300:\n",
    "            print(f\"Tokens low ({limits['remaining']} remaining). Waiting 5 minutes to avoid rate limit...\")\n",
    "            time.sleep(300)  # Wait for 5 minutes before resuming\n",
    "        \n",
    "        submission = reddit.submission(id=post['id'])\n",
    "        comments_df = get_post_comments(submission)\n",
    "        all_comments.append(comments_df)\n",
    "        \n",
    "    return pd.concat(all_comments, ignore_index=True) if all_comments else pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Comments:  30%|██▉       | 2982/9949 [1:01:59<1:07:24,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens low (299.0 remaining). Waiting 5 minutes to avoid rate limit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Comments:  56%|█████▌    | 5572/9949 [2:02:52<46:02,  1.58it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens low (299.0 remaining). Waiting 5 minutes to avoid rate limit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Comments:  68%|██████▊   | 6800/9949 [2:22:27<34:08,  1.54it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens low (299.0 remaining). Waiting 5 minutes to avoid rate limit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Comments:  90%|████████▉ | 8924/9949 [3:12:56<14:35,  1.17it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens low (299.0 remaining). Waiting 5 minutes to avoid rate limit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Comments: 100%|██████████| 9949/9949 [3:34:38<00:00,  1.29s/it]   \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "subreddits = [\n",
    "    \"nutrition\",\n",
    "    \"keto\",\n",
    "    \"healthyfood\",\n",
    "    \"intermittentfasting\",\n",
    "    \"fasting\",\n",
    "    \"PlantBasedDiet\",\n",
    "    \"Volumeeating\",\n",
    "    \"EatCheapAndHealthy\",\n",
    "    \"CICO\",\n",
    "    \"vegetarian\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df_posts = get_top_posts(subreddits, limit=1000, sort_by='top', time_filter='all')\n",
    "\n",
    "# Display DataFrame\n",
    "df_posts.head()\n",
    "\n",
    "# Collect all comments for all posts with progress tracking\n",
    "df_comments = get_all_comments(df_posts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.to_csv(\"b_conventional_comments.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv(\"a_conventional_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'remaining': 999.0, 'reset_timestamp': 1740491401.68855, 'used': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.auth.limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
