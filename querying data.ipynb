{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import datetime        \n",
    "from time import sleep\n",
    "import random\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id='fKSnwxwrgn7DXbSDq8oHnw',         # Your app's client ID\n",
    "    client_secret='xtz8CGEQjdB4SNbM9eHTp82eP0sIdQ', # Your app's client secret\n",
    "    user_agent='Copenhagen University Data Collection Course, analyzing comment civility, Oliver',       # A descriptive user agent\n",
    "    username='OkMinute',    # Your Reddit username\n",
    "    password='Fodbold7'     # Your Reddit password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_posts(subreddit_list, limit=100, sort_by='top', time_filter='all'):\n",
    "    \"\"\"\n",
    "    Fetch top posts from a list of subreddits and return as a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        subreddit_list (list): List of subreddit names.\n",
    "        limit (int): Number of posts to fetch per subreddit.\n",
    "        sort_by (str): Sorting method ('top', 'hot', 'new', 'rising').\n",
    "        time_filter (str): Time filter for sorting ('all', 'day', 'hour', 'month', 'week', 'year'). Only for 'top'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing post data.\n",
    "    \"\"\"\n",
    "    \n",
    "    post_list = []\n",
    "    \n",
    "    for subreddit_name in subreddit_list:\n",
    "        try:\n",
    "            subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "            if sort_by == 'top':\n",
    "                posts = subreddit.top(limit=limit, time_filter=time_filter)\n",
    "            elif sort_by == 'hot':\n",
    "                posts = subreddit.hot(limit=limit)\n",
    "            elif sort_by == 'new':\n",
    "                posts = subreddit.new(limit=limit)\n",
    "            elif sort_by == 'rising':\n",
    "                posts = subreddit.rising(limit=limit)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid sort_by value. Use 'top', 'hot', 'new', or 'rising'.\")\n",
    "            \n",
    "            for post in posts:\n",
    "                post_list.append({\n",
    "                    'subreddit': subreddit_name,\n",
    "                    'title': post.title,\n",
    "                    'score': post.score,\n",
    "                    'id': post.id,\n",
    "                    'url': post.url,\n",
    "                    'num_comments': post.num_comments,\n",
    "                    'created_utc': post.created_utc,\n",
    "                    'selftext': post.selftext,\n",
    "                    'author': post.author.name if post.author else None,\n",
    "                    'upvote_ratio': post.upvote_ratio,\n",
    "                    'permalink': post.permalink,\n",
    "                    'domain': post.domain,\n",
    "                    'flair_text': post.link_flair_text,\n",
    "                    'is_self': post.is_self,\n",
    "                    'view_count': post.view_count,\n",
    "                    'media': post.media\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching posts from r/{subreddit_name}: {e}. Skipping...\")\n",
    "\n",
    "    return pd.DataFrame(post_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_comments(post):\n",
    "    \"\"\"\n",
    "    Fetch all comments for a given post object.\n",
    "    \n",
    "    Parameters:\n",
    "        post (praw.models.Submission): The Reddit post object.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing comment data.\n",
    "    \"\"\"\n",
    "    post.comments.replace_more(limit=0)  # Remove MoreComments objects\n",
    "    \n",
    "    comment_list = []\n",
    "    for comment in post.comments.list():\n",
    "        comment_list.append({\n",
    "            'subreddit': post.subreddit.display_name,\n",
    "            'post_id': post.id,\n",
    "            'post_title': post.title,\n",
    "            'comment_id': comment.id,\n",
    "            'author': comment.author.name if comment.author else None,\n",
    "            'score': comment.score,\n",
    "            'created_utc': comment.created_utc,\n",
    "            'body': comment.body,\n",
    "            'parent_id': comment.parent_id\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(comment_list)\n",
    "\n",
    "def get_all_comments(df_posts):\n",
    "    \"\"\"\n",
    "    Loop over posts DataFrame and collect all comments for each post with progress tracking.\n",
    "    \n",
    "    Parameters:\n",
    "        df_posts (pd.DataFrame): DataFrame containing posts.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing all collected comments.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_comments = []\n",
    "    for _, post in tqdm(df_posts.iterrows(), total=len(df_posts), desc=\"Fetching Comments\"):\n",
    "        submission = reddit.submission(id=post['id'])\n",
    "        comments_df = get_post_comments(submission)\n",
    "        all_comments.append(comments_df)\n",
    "        \n",
    "    \n",
    "\n",
    "    return pd.concat(all_comments, ignore_index=True) if all_comments else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Comments: 100%|██████████| 1594/1594 [21:51<00:00,  1.22it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "subreddit_list = [\n",
    "    'carnivorediet',\n",
    "    'Carnivore',\n",
    "    'ketovore',\n",
    "    'Exvegans',\n",
    "    'Rawprimal',\n",
    "    'rawmeat',\n",
    "    'CarnivoreForum',\n",
    "    'SaturatedFat',\n",
    "    'StopEatingSeedOils',\n",
    "    'Zerocarb',\n",
    "    'NutritionalPsychiatry',\n",
    "    'ScientificNutrition',\n",
    "    'Meatogains',\n",
    "    'Animalbased',\n",
    "    'AnimalbasedDiet',\n",
    "    'Redmeatscience',\n",
    "    'Carnivorescience',\n",
    "    'Meatropology',\n",
    "    'Anti_vegan',\n",
    "    'AntiVegan',\n",
    "    'Primaldietcommunity',\n",
    "    'meatrition',\n",
    "    'StopEatingFiber',\n",
    "    'DietitiansSaidWhatNow'\n",
    "]\n",
    "\n",
    "df_posts = get_top_posts(subreddit_list, limit=100, sort_by='top', time_filter='year')\n",
    "\n",
    "# Display DataFrame\n",
    "df_posts.head()\n",
    "\n",
    "# Collect all comments for all posts with progress tracking\n",
    "df_comments = get_all_comments(df_posts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.to_csv(\"Comments.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv(\"posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b92a34e5d39cac9fbf402cb9677fd5c53b41ade2db1326056da974f0aad65a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
